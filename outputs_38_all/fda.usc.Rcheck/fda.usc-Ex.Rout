
R Under development (unstable) (2018-10-04 r75396) -- "Unsuffered Consequences"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "fda.usc"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> library('fda.usc')
Loading required package: fda
Loading required package: splines
Loading required package: Matrix

Attaching package: ‘fda’

The following object is masked from ‘package:graphics’:

    matplot

Loading required package: MASS
Loading required package: mgcv
Loading required package: nlme
This is mgcv 1.8-24. For overview type 'help("mgcv-package")'.
Loading required package: rpart
> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> base::assign(".old_wd", base::getwd(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("CV.S")
> ### * CV.S
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: CV.S
> ### Title: The cross-validation (CV) score
> ### Aliases: CV.S
> ### Keywords: utilities
> 
> ### ** Examples
> 
> 
> data(tecator)
> x<-tecator$absorp.fdata
> np<-ncol(x)
> tt<-1:np
>  S1 <- S.NW(tt,3,Ker.epa)
>  S2 <- S.LLR(tt,3,Ker.epa)
>  S3 <- S.NW(tt,5,Ker.epa)
>  S4 <- S.LLR(tt,5,Ker.epa)
>  cv1 <- CV.S(x, S1)
>  cv2 <- CV.S(x, S2)
>  cv3 <- CV.S(x, S3)
>  cv4 <- CV.S(x, S4)
>  cv5 <- CV.S(x, S4,trim=0.1,draw=TRUE)
>  cv1;cv2;cv3;cv4;cv5
[1] 111.0077
[1] 88.08087
[1] 113.9769
[1] 85.4358
[1] 83.74001
>  S6 <- S.KNN(tt,1,Ker.unif,cv=TRUE)
>  S7 <- S.KNN(tt,5,Ker.unif,cv=TRUE)
>  cv6 <- CV.S(x, S6)
>  cv7 <- CV.S(x, S7)
>  cv6;cv7
[1] 108.8465
[1] 112.8353
>  
> 
> 
> cleanEx()
> nameEx("DepthFunctional")
> ### * DepthFunctional
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Depth for univariate fdata
> ### Title: Provides the depth measure for functional data
> ### Aliases: Depth depth.FM depth.mode depth.RP depth.RPD depth.RT
> ###   depth.FSD depth.KFSD
> ### Keywords: descriptive
> 
> ### ** Examples
> 
> ## Not run: 
> ##D #Ex: CanadianWeather data
> ##D tt=1:365
> ##D fdataobj<-fdata(t(CanadianWeather$dailyAv[,,1]),tt)
> ##D # Fraiman-Muniz Depth
> ##D out.FM=depth.FM(fdataobj,trim=0.1,draw=TRUE)
> ##D #Modal Depth
> ##D out.mode=depth.mode(fdataobj,trim=0.1,draw=TRUE)
> ##D out.RP=depth.RP(fdataobj,trim=0.1,draw=TRUE)
> ##D out.RT=depth.RT(fdataobj,trim=0.1,draw=TRUE)
> ##D out.FSD=depth.FSD(fdataobj,trim=0.1,draw=TRUE)
> ##D out.KFSD=depth.KFSD(fdataobj,trim=0.1,draw=TRUE)
> ##D ## Double Random Projections
> ##D out.RPD=depth.RPD(fdataobj,deriv=c(0,1),dfunc2=depth.FM,
> ##D trim=0.1,draw=TRUE)
> ##D out<-c(out.FM$mtrim,out.mode$mtrim,out.RP$mtrim,out.RPD$mtrim)
> ##D plot(fdataobj,col="grey")
> ##D lines(out)
> ##D cdep<-cbind(out.FM$dep,out.mode$dep,out.RP$dep,out.RT$dep,out.FSD$dep,out.KFSD$dep)
> ##D colnames(cdep)<-c("FM","mode","RP","RT","FSD","KFSD")
> ##D pairs(cdep)
> ##D round(cor(cdep),2)
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("DepthFunctionalIntegrate")
> ### * DepthFunctionalIntegrate
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Depth for multivariate fdata
> ### Title: Provides the depth measure for a list of p-functional data
> ###   objects
> ### Aliases: Depth.pfdata depth.FMp depth.modep depth.RPp
> ### Keywords: descriptive
> 
> ### ** Examples
> 
> ## Not run: 
> ##D data(tecator)
> ##D xx<-tecator$absorp
> ##D xx1<-fdata.deriv(xx,1)
> ##D lx<-list(xx=xx,xx=xx1)
> ##D # Fraiman-Muniz Depth
> ##D par.df<-list(scale =TRUE)
> ##D out.FM1p=depth.FMp(lx,trim=0.1,draw=TRUE, par.dfunc = par.df)
> ##D out.FM2p=depth.FMp(lx,trim=0.1,dfunc="mdepth.LD",
> ##D par.dfunc = par.df, draw=TRUE)
> ##D 
> ##D # Random Project Depth
> ##D out.RP1p=depth.RPp(lx,trim=0.1,dfunc="mdepth.TD",
> ##D draw=TRUE,par.dfunc = par.df)
> ##D out.RP2p=depth.RPp(lx,trim=0.1,dfunc="mdepth.LD",
> ##D draw=TRUE,par.dfunc = par.df)
> ##D 
> ##D #Modal Depth
> ##D out.mode1p=depth.modep(lx,trim=0.1,draw=T,scale=T)
> ##D out.mode2p=depth.modep(lx,trim=0.1,method="manhattan",
> ##D draw=T,scale=T)
> ##D 
> ##D par(mfrow=c(2,3))
> ##D plot(out.FM1p$dep,out.FM2p$dep)
> ##D plot(out.RP1p$dep,out.RP2p$dep)
> ##D plot(out.mode1p$dep,out.mode2p$dep)
> ##D plot(out.FM1p$dep,out.RP1p$dep)
> ##D plot(out.RP1p$dep,out.mode1p$dep)
> ##D plot(out.FM1p$dep,out.mode1p$dep)
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("DepthMultivariate")
> ### * DepthMultivariate
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Depth for a multivariate dataset
> ### Title: Provides the depth measure for multivariate data
> ### Aliases: Depth.Multivariate mdepth.HS mdepth.MhD mdepth.SD mdepth.LD
> ###   mdepth.TD mdepth.RP
> ### Keywords: descriptive
> 
> ### ** Examples
> 
> data(iris)
> group<-iris[,5]
> x<-iris[,1:2]
>                                   
> MhD<-mdepth.MhD(x)
> PD<-mdepth.RP(x)
> HD<-mdepth.HS(x)
> SD<-mdepth.SD(x)
> 
> x.setosa<-x[group=="setosa",]
> x.versicolor<-x[group=="versicolor",] 
> x.virginica<-x[group=="virginica",]
> d1<-mdepth.SD(x,x.setosa)$dep
> d2<-mdepth.SD(x,x.versicolor)$dep
> d3<-mdepth.SD(x,x.virginica)$dep
> 
> 
> 
> 
> 
> cleanEx()
> nameEx("Descriptive")
> ### * Descriptive
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Descriptive
> ### Title: Descriptive measures for functional data.
> ### Aliases: func.mean.formula Descriptive func.mean func.trim.FM
> ###   func.trim.mode func.trim.RP func.trim.RT func.trim.RPD func.med.FM
> ###   func.med.mode func.med.RP func.med.RT func.med.RPD func.var
> ###   func.trimvar.FM func.trimvar.mode func.trimvar.RP func.trimvar.RT
> ###   func.trimvar.RPD
> ### Keywords: descriptive
> 
> ### ** Examples
> 
> 
> # Example with Montreal Daily Temperature (fda-package)
> fdataobj<-fdata(MontrealTemp)
> 
> # Measures of central tendency by group
> fac<-factor(c(rep(1,len=17),rep(2,len=17)))
> ldata=list("df"=data.frame(fac),"fdataobj"=fdataobj)
> a1<-func.mean.formula(fdataobj~fac,data=ldata)
> plot(a1)
> 
> ## Not run: 
> ##D # Measures of central tendency
> ##D a1<-func.mean(fdataobj)
> ##D a2<-func.trim.FM(fdataobj)
> ##D a3<-func.trim.mode(fdataobj)
> ##D a4<-func.trim.RP(fdataobj)
> ##D # a5<-func.trim.RPD(fdataobj,deriv=c(0,1)) # Time-consuming
> ##D a6<-func.med.FM(fdataobj)
> ##D a7<-func.med.mode(fdataobj)
> ##D a8<-func.med.RP(fdataobj)
> ##D # a9<-func.med.RPD(fdataobj,deriv=c(0,1)) # Time-consuming
> ##D # a10<-func.med.RT(fdataobj)
> ##D 
> ##D dev.new()
> ##D par(mfrow=c(1,2))
> ##D plot(c(a1,a2,a3,a4),ylim=c(-26,29),main="Central tendency: trimmed mean")
> ##D plot(c(a1,a6,a7,a8),ylim=c(-26,29),main="Central tendency: median")
> ##D 
> ##D 
> ##D ## Measures of dispersion
> ##D b1<-func.var(fdataobj)
> ##D b2<-func.trimvar.FM(fdataobj)
> ##D b3<-func.trimvar.FM(fdataobj,trim=0.1)
> ##D b4<-func.trimvar.mode(fdataobj)
> ##D b5<-func.trimvar.mode(fdataobj,p=1)
> ##D b6<-func.trimvar.RP(fdataobj)
> ##D b7<-func.trimvar.RPD(fdataobj)
> ##D b8<-func.trimvar.RPD(fdataobj)
> ##D b9<-func.trimvar.RPD(fdataobj,deriv=c(0,1))
> ##D dev.new()
> ##D par(mfrow=c(1,2))
> ##D plot(c(b1,b2,b3,b4,b5),ylim=c(0,79),main="Measures of dispersion I")
> ##D plot(c(b1,b6,b7,b8,b9),ylim=c(0,79),main="Measures of dispersion II")
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("FDR")
> ### * FDR
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: FDR
> ### Title: False Discorvery Rate (FDR)
> ### Aliases: FDR pvalue.FDR
> 
> ### ** Examples
> 
>  p=seq(1:50)/1000
>  FDR(p)
[1] TRUE
>  pvalue.FDR(p)
[1] 0.05
>  FDR(p,alpha=0.9999)
[1] FALSE
>  FDR(p,alpha=0.9)
[1] TRUE
>  FDR(p,alpha=0.9,dep=-1)
[1] FALSE
> 
> 
> 
> cleanEx()
> nameEx("GCCV.S")
> ### * GCCV.S
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: GCCV.S
> ### Title: The generalized correlated cross-validation (GCCV) score.
> ### Aliases: GCCV.S
> ### Keywords: utilities
> 
> ### ** Examples
> 
> ## Not run: 
> ##D data(tecator)
> ##D x=tecator$absorp.fdata
> ##D x.d2<-fdata.deriv(x,nderiv=)
> ##D tt<-x[["argvals"]]
> ##D dataf=as.data.frame(tecator$y)
> ##D y=tecator$y$Fat
> ##D # plot the response
> ##D plot(ts(tecator$y$Fat))
> ##D 
> ##D nbasis.x=11;nbasis.b=7
> ##D basis1=create.bspline.basis(rangeval=range(tt),nbasis=nbasis.x)
> ##D basis2=create.bspline.basis(rangeval=range(tt),nbasis=nbasis.b)
> ##D basis.x=list("x.d2"=basis1)
> ##D basis.b=list("x.d2"=basis2)
> ##D ldata=list("df"=dataf,"x.d2"=x.d2)
> ##D # No correlation
> ##D res.gls=fregre.gls(Fat~x.d2,data=ldata, 
> ##D                    basis.x=basis.x,basis.b=basis.b)
> ##D # AR1 correlation                   
> ##D res.gls=fregre.gls(Fat~x.d2,data=ldata, correlation=corAR1(),
> ##D                    basis.x=basis.x,basis.b=basis.b)
> ##D GCCV.S(y,res.gls$H,"GCCV1",W=res.gls$W)
> ##D res.gls$gcv
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("GCV.S")
> ### * GCV.S
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: GCV.S
> ### Title: The generalized cross-validation (GCV) score.
> ### Aliases: GCV.S
> ### Keywords: utilities
> 
> ### ** Examples
> 
> 
> data(phoneme)
> mlearn<-phoneme$learn
> tt<-1:ncol(mlearn)
> S1 <- S.NW(tt,2.5)
> S2 <- S.LLR(tt,2.5)
> gcv1 <- GCV.S(mlearn, S1)
> gcv2 <- GCV.S(mlearn, S2)
> gcv3 <- GCV.S(mlearn, S1,criteria="AIC")
> gcv4 <- GCV.S(mlearn, S2,criteria="AIC")
> gcv1; gcv2; gcv3; gcv4
[1] 2.44487
attr(,"df")
[1] 24.39245
[1] 3.078098
attr(,"df")
[1] 63.67978
[1] 2.373294
attr(,"df")
[1] 24.39245
[1] 2.382696
attr(,"df")
[1] 63.67978
>  
> 
> 
> cleanEx()
> nameEx("Kernel")
> ### * Kernel
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Kernel
> ### Title: Symmetric Smoothing Kernels.
> ### Aliases: Kernel Ker.norm Ker.cos Ker.epa Ker.tri Ker.tri Ker.quar
> ###   Ker.unif
> ### Keywords: kernel
> 
> ### ** Examples
> 
> y=qnorm(seq(.1,.9,len=100))
> a<-Kernel(u=y)
> b<-Kernel(type.Ker="Ker.tri",u=y)
> c=Ker.cos(y)
> 
> 
> 
> cleanEx()
> nameEx("Kernel.asymmetric")
> ### * Kernel.asymmetric
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Kernel.asymmetric
> ### Title: Asymmetric Smoothing Kernel
> ### Aliases: AKer.norm AKer.cos AKer.epa AKer.tri AKer.tri AKer.quar
> ###   AKer.unif Kernel.asymmetric
> ### Keywords: kernel
> 
> ### ** Examples
> 
> y=qnorm(seq(.1,.9,len=100))
> a<-Kernel.asymmetric(u=y)
> b<-Kernel.asymmetric(type.Ker="AKer.tri",u=y)
> c=AKer.cos(y)
> 
> 
> 
> cleanEx()
> nameEx("Kernel.integrate")
> ### * Kernel.integrate
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Kernel.integrate
> ### Title: Integrate Smoothing Kernels.
> ### Aliases: Kernel.integrate IKer.norm IKer.cos IKer.epa IKer.tri IKer.tri
> ###   IKer.quar IKer.unif
> ### Keywords: kernel
> 
> ### ** Examples
> 
> 
> 
> y=qnorm(seq(.1,.9,len=100))
> d=IKer.tri(y)
> e=IKer.cos(y)
> e2=Kernel.integrate(u=y,Ker=Ker.cos)
> e-e2
  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 [38] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 [75] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
> f=IKer.epa(y)
> f2=Kernel.integrate(u=y,Ker=Ker.epa)
> f-f2
  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 [38] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 [75] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
> 
> 
> plot(d,type="l",ylab="Integrate Kernel")
> lines(e,col=2,type="l")
> lines(f,col=4,type="l")
> 
> 
> 
> 
> 
> cleanEx()
> nameEx("LMDC.select")
> ### * LMDC.select
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: LMDC.select
> ### Title: Impact points selection of functional predictor and regression
> ###   using local maxima distance correlation (LMDC)
> ### Aliases: LMDC.select LMDC.regre
> ### Keywords: regression
> 
> ### ** Examples
> 
> ## Not run: 
> ##D data(tecator)
> ##D absorp=fdata.deriv(tecator$absorp.fdata,2)
> ##D ind=1:129
> ##D x=absorp[ind,]
> ##D y=tecator$y$Fat[ind]
> ##D newx=absorp[-ind,]
> ##D newy=tecator$y$Fat[-ind]
> ##D 
> ##D ## Functional PC regression
> ##D res.pc=fregre.pc(x,y,1:6)
> ##D pred.pc=predict.fregre.fd(res.pc,newx)
> ##D 
> ##D # Functional regression with basis representation
> ##D res.basis=fregre.basis.cv(x,y)
> ##D pred.basis=predict.fregre.fd(res.basis,newx)
> ##D 
> ##D # Functional nonparametric regression
> ##D res.np=fregre.np.cv(x,y)
> ##D pred.np=predict.fregre.fd(res.np,newx)
> ##D 
> ##D dat    <- data.frame("y"=y,x$data)
> ##D newdat <- data.frame("y"=newy,newx$data)
> ##D 
> ##D res.gam=fregre.gsam(y~s(x),data=list("df"=dat,"x"=x))
> ##D pred.gam=predict.fregre.gsam(res.gam,list("x"=newx))
> ##D 
> ##D 
> ##D 
> ##D dc.raw <- LMDC.select("y",data=dat, tol = 0.05, pvalue= 0.05,
> ##D                       plot=F, smo=T,verbose=F)
> ##D covar <- paste("X",dc.raw$maxLocal,sep="")                      
> ##D # Preselected design/impact points 
> ##D covar
> ##D ftest<-flm.test(dat[,-1],dat[,"y"], B=500, verbose=F,
> ##D     plot.it=F,type.basis="pc",est.method="pc",p=4,G=50)
> ##D     
> ##D if (ftest$p.value>0.05) { 
> ##D   # Linear relationship, step-wise lm is recommended
> ##D   out <- LMDC.regre("y",covar,dat,newdat,pvalue=.05,
> ##D               method ="lm",plot=F,verbose=F)
> ##D } else {
> ##D  # Non-Linear relationship, step-wise gam is recommended
> ##D   out <- LMDC.regre("y",covar,dat,newdat,pvalue=.05,
> ##D               method ="gam",plot=F,verbose=F) }  
> ##D              
> ##D # Final  design/impact points
> ##D out$xvar
> ##D 
> ##D # Predictions
> ##D mean((newy-pred.pc)^2)                
> ##D mean((newy-pred.basis)^2) 
> ##D mean((newy-pred.np)^2)              
> ##D mean((newy-pred.gam)^2) 
> ##D mean((newy-out$pred)^2)
> ## End(Not run)                          
> 
> 
> 
> cleanEx()
> nameEx("MCO")
> ### * MCO
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: MCO
> ### Title: Mithochondiral calcium overload (MCO) data set
> ### Aliases: MCO
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data(MCO)
> names(MCO)
[1] "intact"      "permea"      "classintact" "classpermea"
> par(mfrow=c(1,2))
> plot(MCO$intact,col=MCO$classintact)
> plot(MCO$permea,col=MCO$classpermea)
> 
> 
> 
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()
> nameEx("Outliers.fdata")
> ### * Outliers.fdata
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Outliers.fdata
> ### Title: Detecting outliers for functional dataset
> ### Aliases: Outliers.fdata outliers.depth.pond outliers.depth.trim
> ###   outliers.thres.lrt outliers.lrt quantile.outliers.trim
> ###   quantile.outliers.pond
> ### Keywords: outliers
> 
> ### ** Examples
> 
> ## Not run: 
> ##D data(aemet)
> ##D nb=20 # Time consuming
> ##D out.trim<-outliers.depth.trim(aemet$temp,dfunc=depth.FM,nb=nb)
> ##D plot(aemet$temp,col=1,lty=1)
> ##D lines(aemet$temp[out.trim[[1]]],col=2)
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("P.penalty")
> ### * P.penalty
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: P.penalty
> ### Title: Penalty matrix for higher order differences
> ### Aliases: P.penalty
> ### Keywords: math
> 
> ### ** Examples
> 
> P.penalty((1:10)/10,P=c(0,0,1))
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
 [1,]    1   -2    1    0    0    0    0    0    0     0
 [2,]   -2    5   -4    1    0    0    0    0    0     0
 [3,]    1   -4    6   -4    1    0    0    0    0     0
 [4,]    0    1   -4    6   -4    1    0    0    0     0
 [5,]    0    0    1   -4    6   -4    1    0    0     0
 [6,]    0    0    0    1   -4    6   -4    1    0     0
 [7,]    0    0    0    0    1   -4    6   -4    1     0
 [8,]    0    0    0    0    0    1   -4    6   -4     1
 [9,]    0    0    0    0    0    0    1   -4    5    -2
[10,]    0    0    0    0    0    0    0    1   -2     1
> # a more detailed example can be found under script file 
> 
> 
> cleanEx()
> nameEx("PCvM.statistic")
> ### * PCvM.statistic
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: PCvM.statistic
> ### Title: PCvM statistic for the Functional Linear Model with scalar
> ###   response
> ### Aliases: PCvM.statistic Adot
> ### Keywords: htest
> 
> ### ** Examples
> 
> 
> # Functional process
> X=rproc2fdata(n=10,t=seq(0,1,l=101))
> 
> # Adot
> Adot.vec=Adot(X)
> 
> # Obtain the entire matrix Adot
> Ad=diag(rep(Adot.vec[1],dim(X$data)[1]))
> Ad[upper.tri(Ad,diag=FALSE)]=Adot.vec[-1]
> Ad=t(Ad)
> Ad=Ad+t(Ad)-diag(diag(Ad))
> Ad
          [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8]
 [1,] 34.55752 23.11694 23.86602 22.13057 22.84318 23.29603 21.92317 23.55528
 [2,] 23.11694 34.55752 22.44900 22.20851 23.74225 22.72428 22.82010 23.39524
 [3,] 23.86602 22.44900 34.55752 23.07776 22.94914 23.27540 23.60196 24.01926
 [4,] 22.13057 22.20851 23.07776 34.55752 22.73507 22.49199 23.62905 23.95065
 [5,] 22.84318 23.74225 22.94914 22.73507 34.55752 23.22676 22.13884 22.78849
 [6,] 23.29603 22.72428 23.27540 22.49199 23.22676 34.55752 22.48571 22.64937
 [7,] 21.92317 22.82010 23.60196 23.62905 22.13884 22.48571 34.55752 22.81234
 [8,] 23.55528 23.39524 24.01926 23.95065 22.78849 22.64937 22.81234 34.55752
 [9,] 23.00154 23.24157 22.52178 23.91473 22.05611 21.84390 23.36816 23.44638
[10,] 24.03184 23.07743 23.90314 23.41496 22.03899 22.49265 23.54075 23.57600
          [,9]    [,10]
 [1,] 23.00154 24.03184
 [2,] 23.24157 23.07743
 [3,] 22.52178 23.90314
 [4,] 23.91473 23.41496
 [5,] 22.05611 22.03899
 [6,] 21.84390 22.49265
 [7,] 23.36816 23.54075
 [8,] 23.44638 23.57600
 [9,] 34.55752 23.35332
[10,] 23.35332 34.55752
> 
> # Statistic
> PCvM.statistic(X,residuals=rnorm(10),p=5)
[1] 26.73364
> 
> 
> 
> 
> cleanEx()
> nameEx("S.basis")
> ### * S.basis
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: S.basis
> ### Title: Smoothing matrix with roughness penalties by basis
> ###   representation.
> ### Aliases: S.basis
> ### Keywords: smooth
> 
> ### ** Examples
> 
> 
> np=101
> tt=seq(0,1,len=np)
> 
> nbasis=11
> base1 <- create.bspline.basis(c(0, np), nbasis)
> base2 <- create.fourier.basis(c(0, np), nbasis)
> 
> S1<-S.basis(tt,basis=base1,lambda=3)
> image(S1) 
> S2<-S.basis(tt,basis=base2,lambda=3)
> image(S2)
> 
> 
> 
> 
> 
> cleanEx()
> nameEx("S.np")
> ### * S.np
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: S.np
> ### Title: Smoothing matrix by nonparametric methods.
> ### Aliases: S.np S.LLR S.NW S.KNN
> ### Keywords: smooth
> 
> ### ** Examples
> 
> 
> tt=1:101
> S=S.LLR(tt,h=5)
> S2=S.LLR(tt,h=10,Ker=Ker.tri)
> S3=S.NW(tt,h=10,Ker=Ker.tri)
> S4=S.KNN(tt,h=5,Ker=Ker.tri)
> par(mfrow=c(2,2))
> image(S)
> image(S2)
> image(S3)
> image(S4)
> 
> 
> 
> 
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()
> nameEx("Var.y")
> ### * Var.y
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Var.y
> ### Title: Sampling Variance estimates
> ### Aliases: Var.y Var.e
> 
> ### ** Examples
> 
> 
> a1<-seq(0,1,by=.01)
> a2=rnorm(length(a1),sd=0.2)
> f1<-(sin(2*pi*a1))+rnorm(length(a1),sd=0.2)
> nc<-50
> np<-length(f1)
> tt=1:101
> mdata<-matrix(NA,ncol=np,nrow=nc)
> for (i in 1:nc) mdata[i,]<- (sin(2*pi*a1))+rnorm(length(a1),sd=0.2)
> mdata<-fdata(mdata,tt)
> S=S.NW(tt,h=0.15)
> var.e<-Var.e(mdata,S)
> var.y<-Var.y(mdata,S)
> var.y2<-Var.y(mdata,S,var.e) #the same
> 
> 
> 
> cleanEx()
> nameEx("aemet")
> ### * aemet
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: aemet
> ### Title: aemet data
> ### Aliases: aemet
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data(aemet)
> names(aemet)
[1] "df"         "temp"       "wind.speed" "logprec"   
> names(aemet$df)
[1] "ind"       "name"      "province"  "altitude"  "year.ini"  "year.end" 
[7] "longitude" "latitude" 
> par(mfrow=c(3,1))
> plot(aemet$temp)
> plot(aemet$wind.speed)
> plot(aemet$logprec)
> 
> 
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()
> nameEx("anova.RPm")
> ### * anova.RPm
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: anova.RPm
> ### Title: Functional ANOVA with Random Project.
> ### Aliases: anova.RPm anova.RPm.boot summary.anova
> ### Keywords: anova
> 
> ### ** Examples
> 
> 
> # ex anova.hetero
> data(phoneme)
> names(phoneme)
[1] "learn"      "test"       "classlearn" "classtest" 
> data=as.data.frame(phoneme$learn[["data"]])
> group=phoneme$classlearn
> n=nrow(data)
> group.rand=as.factor(sample(rep(1:3,len=n),n))
> RP=c(2,5,15,30)
> 
> #ex 1: real factor and random factor
> m03=data.frame(group,group.rand)
> resul1=anova.RPm(data,~group+group.rand,m03,RP=c(5,30))
> summary.anova(resul1)
     - SUMMARY anova.RPm - 

 p-value for Bonferroni method 
     group group.rand
RP5      0    0.76943
RP30     0    0.42348

  p-value for False Discovery Rate method 
     group group.rand
RP5      0    0.36025
RP30     0    0.42348

> 
> #ex 2: real factor with special contrast
> m0=data.frame(group)
> cr5=contr.sum(5)   #each level vs last level
> resul03c1=anova.RPm(data,~group,m0,contrast=list(group=cr5))
> summary.anova(resul03c1)
     - SUMMARY anova.RPm - 

 p-value for Bonferroni method 
     group C1.group C2.group C3.group C4.group
RP30     0        0        0        0        0

  p-value for False Discovery Rate method 
     group C1.group C2.group C3.group C4.group
RP30     0        0        0        0        0

> 
> #ex 3: random factor with special contrast
> m0=data.frame(group.rand)
> cr3=contr.sum(3)   #each level vs last level
> resul03c1=anova.RPm(data,~group.rand,m0,contrast=list(group.rand=cr3))
> summary.anova(resul03c1)
     - SUMMARY anova.RPm - 

 p-value for Bonferroni method 
     group.rand C1.group.rand C2.group.rand
RP30    0.02188             1       0.02123

  p-value for False Discovery Rate method 
     group.rand C1.group.rand C2.group.rand
RP30    0.02188       0.88308       0.02123

> 
> 
> 
> cleanEx()
> nameEx("anova.hetero")
> ### * anova.hetero
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: anova.hetero
> ### Title: ANOVA for heteroscedastic data
> ### Aliases: anova.hetero
> ### Keywords: anova
> 
> ### ** Examples
> 
> 
> data(phoneme)
> ind=1 # beetwen 1:150
> fdataobj=data.frame(phoneme$learn[["data"]][,ind])
> n=dim(fdataobj)[1]
> group<-factor(phoneme$classlearn)
> 
> #ex 1: real factor and random factor
> group.rand=as.factor(sample(rep(1:3,n),n))
> f=data.frame(group,group.rand)
> mm=data.frame(fdataobj,f)
> colnames(mm)=c("value","group","group.rand")
> out1=anova.hetero(object=mm[,-2],value~group.rand,pr=FALSE)
> out2=anova.hetero(object=mm[,-3],value~group,pr=FALSE)
> out1
$ans
               Est.      df1     df2   p.value
group.rand 1.447188 1.983288 235.192 0.2373813

attr(,"class")
[1] "anova.hetero"
> out2
$ans
          Est.      df1      df2      p.value
group 14.00342 3.787966 227.9845 7.430929e-10

attr(,"class")
[1] "anova.hetero"
> 
> #ex 2: real factor, random factor and  special contrasts
> cr5=contr.sum(5)  #each level vs last level
> cr3=c(1,0,-1)			#first level vs last level
> out.contrast=anova.hetero(object=mm[,-3],value~group,pr=FALSE,
+ contrast=list(group=cr5))
> out.contrast
$ans
               Est.      df1       df2      p.value
group    14.0034194 3.787966 227.98454 7.430929e-10
C1.group  0.4092483 1.000000  97.44492 5.238525e-01
C2.group  1.8584975 1.000000  97.90871 1.759251e-01
C3.group 21.0917395 1.000000  83.20769 1.539245e-05
C4.group  8.7549850 1.000000  97.67193 3.873737e-03

$contrast
$contrast$group
  C1.group C2.group C3.group C4.group
1        1        0        0        0
2        0        1        0        0
3        0        0        1        0
4        0        0        0        1
5       -1       -1       -1       -1


attr(,"class")
[1] "anova.hetero"
>     
> 
> 
> cleanEx()
> nameEx("anova.onefactor")
> ### * anova.onefactor
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: anova.onefactor
> ### Title: One-way anova model for functional data
> ### Aliases: anova.onefactor
> ### Keywords: anova
> 
> ### ** Examples
> 
> ## Not run: 
> ##D data(MCO)
> ##D grupo<-MCO$classintact
> ##D datos<-MCO$intact
> ##D res=anova.onefactor(datos,grupo,nboot=50,plot=TRUE)
> ##D 
> ##D grupo<-MCO$classpermea
> ##D datos<-MCO$permea
> ##D res=anova.onefactor(datos,grupo,nboot=50,plot=TRUE)
> ## End(Not run)  
> 
> 
> 
> cleanEx()
> nameEx("classif.DD")
> ### * classif.DD
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: classif.DD
> ### Title: DD-Classifier Based on DD-plot
> ### Aliases: classif.DD
> ### Keywords: classif
> 
> ### ** Examples
> 
> 
> ## Not run: 
> ##D 
> ##D # DD-classif for functional data
> ##D data(tecator)
> ##D ab=tecator$absorp.fdata
> ##D ab1=fdata.deriv(ab,nderiv=1)
> ##D ab2=fdata.deriv(ab,nderiv=2)
> ##D gfat=factor(as.numeric(tecator$y$Fat>=15))
> ##D 
> ##D # DD-classif for p=1 functional  data set
> ##D out01=classif.DD(gfat,ab,depth="mode",classif="np")
> ##D out02=classif.DD(gfat,ab2,depth="mode",classif="np")
> ##D # DD-plot in gray scale
> ##D ctrl<-list(draw=T,col=gray(c(0,.5)),alpha=.2)
> ##D out02bis=classif.DD(gfat,ab2,depth="mode",classif="np",control=ctrl)
> ##D 
> ##D # 2 depth functions (same curves) 
> ##D out03=classif.DD(gfat,list(ab2,ab2),depth=c("RP","mode"),classif="np")
> ##D # DD-classif for p=2 functional data set
> ##D ldata<-list("ab"=ab2,"ab2"=ab2)
> ##D # Weighted version 
> ##D out04=classif.DD(gfat,ldata,depth="mode",classif="np",w=c(0.5,0.5))
> ##D # Model version
> ##D out05=classif.DD(gfat,ldata,depth="mode",classif="np")
> ##D # Integrated version (for multivariate functional data)
> ##D out06=classif.DD(gfat,ldata,depth="modep",classif="np")
> ##D 
> ##D # DD-classif for multivariate data
> ##D data(iris)
> ##D group<-iris[,5]
> ##D x<-iris[,1:4]
> ##D out10=classif.DD(group,x,depth="RP",classif="lda")
> ##D summary.classif(out10)
> ##D out11=classif.DD(group,list(x,x),depth=c("MhD","RP"),classif="lda")
> ##D summary.classif(out11)
> ##D 
> ##D # DD-classif for functional data: g levels 
> ##D data(phoneme)
> ##D mlearn<-phoneme[["learn"]]
> ##D glearn<-as.numeric(phoneme[["classlearn"]])-1
> ##D out20=classif.DD(glearn,mlearn,depth="FM",classif="glm")
> ##D out21=classif.DD(glearn,list(mlearn,mlearn),depth=c("FM","RP"),classif="glm")
> ##D summary.classif(out20)
> ##D summary.classif(out21)
> ## End(Not run)
> 
> 
> 
> 
> cleanEx()
> nameEx("classif.depth")
> ### * classif.depth
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: classif.depth
> ### Title: Classifier from Functional Data
> ### Aliases: classif.depth
> ### Keywords: classif
> 
> ### ** Examples
> 
>  
> ## Not run: 
> ##D data(phoneme)
> ##D mlearn<-phoneme[["learn"]]
> ##D mtest<-phoneme[["test"]]
> ##D glearn<-phoneme[["classlearn"]]
> ##D gtest<-phoneme[["classtest"]]
> ##D 
> ##D a1<-classif.depth(glearn,mlearn,depth="RP")
> ##D table(a1$group.est,glearn)
> ##D a2<-classif.depth(glearn,mlearn,depth="RP",CV=TRUE)
> ##D a3<-classif.depth(glearn,mlearn,depth="RP",CV=FALSE)
> ##D a4<-classif.depth(glearn,mlearn,mtest,"RP")
> ##D a5<-classif.depth(glearn,mlearn,mtest,"RP",CV=TRUE)     
> ##D table(a5$group.est,glearn)
> ##D a6<-classif.depth(glearn,mlearn,mtest,"RP",CV=FALSE)
> ##D table(a6$group.est,glearn)
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("classif.gkam")
> ### * classif.gkam
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: classif.gkam
> ### Title: Classification Fitting Functional Generalized Kernel Additive
> ###   Models
> ### Aliases: classif.gkam
> ### Keywords: classif
> 
> ### ** Examples
> 
> 
> ## Time-consuming: selection of 2 levels 
>  data(phoneme)
>  mlearn<-phoneme[["learn"]][1:100]
>  glearn<-as.numeric(phoneme[["classlearn"]][1:100])
>  dataf<-data.frame(glearn)
>  dat=list("df"=dataf,"x"=mlearn)
> # a1<-classif.gkam(glearn~x,data=dat)
> # summary(a1)
>  mtest<-phoneme[["test"]][1:100]
>  gtest<-as.numeric(phoneme[["classtest"]][1:100])
>  newdat<-list("x"=mtest)
> # p1<-predict.classif(a1,newdat)
> # table(gtest,p1)
> 
> 
> 
> 
> cleanEx()
> nameEx("classif.glm")
> ### * classif.glm
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: classif.glm
> ### Title: Classification Fitting Functional Generalized Linear Models
> ### Aliases: classif.glm
> ### Keywords: classif
> 
> ### ** Examples
> 
> data(phoneme)
> mlearn<-phoneme[["learn"]]
> glearn<-phoneme[["classlearn"]]
> mtest<-phoneme[["test"]]
> gtest<-phoneme[["classtest"]]
> dataf<-data.frame(glearn)
> dat=list("df"=dataf,"x"=mlearn)
> a1<-classif.glm(glearn~x, data = dat)
Warning: glm.fit: algorithm did not converge
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
> newdat<-list("x"=mtest)
> p1<-predict.classif(a1,newdat)
> table(gtest,p1)
     p1
gtest  1  2  3  4  5
    1 50  0  0  0  0
    2  0 48  1  0  1
    3  0  0 50  0  0
    4  0  0  0 47  3
    5  0  0  0 11 39
> sum(p1==gtest)/250
[1] 0.936
> 
> 
> 
> cleanEx()
> nameEx("classif.gsam")
> ### * classif.gsam
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: classif.gsam
> ### Title: Classification Fitting Functional Generalized Additive Models
> ### Aliases: classif.gsam
> ### Keywords: classif
> 
> ### ** Examples
> 
> 
> data(phoneme)
> mlearn<-phoneme[["learn"]]
> glearn<-phoneme[["classlearn"]]
> mtest<-phoneme[["test"]]
> gtest<-phoneme[["classtest"]]
> dataf<-data.frame(glearn)
> dat=list("df"=dataf,"x"=mlearn)
> a1<-classif.gsam(glearn~s(x,k=3),data=dat)
> summary(a1)
     - SUMMARY - 

-Probability of correct classification by group (prob.classification):
   1    2    3    4    5 
1.00 0.98 1.00 0.84 0.82 

-Confusion matrix between the theoretical groups (by rows)
  and estimated groups (by column) 
   
     1  2  3  4  5
  1 50  0  0  0  0
  2  0 49  1  0  0
  3  0  0 50  0  0
  4  0  0  0 42  8
  5  0  0  0  9 41

-Probability of correct classification:  0.928 

> newdat<-list("x"=mtest)
> p1<-predict.classif(a1,newdat)
> table(gtest,p1)
     p1
gtest  1  2  3  4  5
    1 50  0  0  0  0
    2  0 49  0  0  1
    3  0  0 50  0  0
    4  0  0  0 47  3
    5  0  2  0 10 38
> sum(p1==gtest)/250
[1] 0.936
> 
> 
> 
> cleanEx()
> nameEx("classif.np")
> ### * classif.np
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: classif.np
> ### Title: Kernel Classifier from Functional Data
> ### Aliases: classif.np classif.kernel classif.knn
> ### Keywords: classif
> 
> ### ** Examples
> 
> data(phoneme)
> mlearn<-phoneme[["learn"]]
> glearn<-phoneme[["classlearn"]]
> 
> h=9:19
> out=classif.np(glearn,mlearn,h=h)
> summary.classif(out)
     - SUMMARY - 

-Probability of correct classification by group (prob.classification):
y
   1    2    3    4    5 
1.00 1.00 0.96 0.78 0.78 

-Confusion matrix between the theoretical groups (by rows)
  and estimated groups (by column) 
   
     1  2  3  4  5
  1 50  0  0  0  0
  2  0 50  0  0  0
  3  1  1 48  0  0
  4  0  0  0 39 11
  5  0  0  1 10 39

-Vector of probability of correct classification
    by banwidth (h):
    9    10    11    12    13    14    15    16    17    18    19 
0.896 0.896 0.892 0.896 0.900 0.904 0.904 0.904 0.900 0.892 0.892 

-Optimal bandwidth: h.opt= 14 with highest probability of
correct classification: max.prob= 0.904 

> #round(out$prob.group,4)
> 
> 
> 
> cleanEx()
> nameEx("classif.tree")
> ### * classif.tree
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: classif.tree
> ### Title: Classification Fitting Functional Recursive Partitioning and
> ###   Regression Trees
> ### Aliases: classif.tree
> ### Keywords: classif
> 
> ### ** Examples
> 
> 
> data(phoneme)
> mlearn<-phoneme[["learn"]]
> glearn<-phoneme[["classlearn"]]
> mtest<-phoneme[["test"]]
> gtest<-phoneme[["classtest"]]
> dataf<-data.frame(glearn)
> dat=list("df"=dataf,"x"=mlearn)
> a1<-classif.tree(glearn~x,data=dat)
> summary(a1)
     - SUMMARY - 

-Probability of correct classification by group (prob.classification):
   1    2    3    4    5 
0.96 0.92 1.00 0.76 0.82 

-Confusion matrix between the theoretical groups (by rows)
  and estimated groups (by column) 
   
     1  2  3  4  5
  1 48  2  0  0  0
  2  0 46  2  1  1
  3  0  0 50  0  0
  4  0  0  0 38 12
  5  0  1  0  8 41

-Probability of correct classification:  0.892 

> newdat<-list("x"=mtest)
> p1<-predict.classif(a1,newdat,type="class")
> table(gtest,p1)
     p1
gtest  1  2  3  4  5
    1 45  3  2  0  0
    2  0 41  0  2  7
    3  0  0 49  0  1
    4  0  2  0 37 11
    5  0  1  0  8 41
> sum(p1==gtest)/250
[1] 0.852
> 
> 
> 
> cleanEx()
> nameEx("cond.F")
> ### * cond.F
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: cond.F
> ### Title: Conditional Distribution Function
> ### Aliases: cond.F
> ### Keywords: distribution
> 
> ### ** Examples
> 
> 
> # Read data
> n= 500
> t= seq(0,1,len=101)
> beta = t*sin(2*pi*t)^2
> x = matrix(NA, ncol=101, nrow=n)
> y=numeric(n)
> x0<-rproc2fdata(n,seq(0,1,len=101),sigma="wiener")
> x1<-rproc2fdata(n,seq(0,1,len=101),sigma=0.1)
> x<-x0*3+x1
> fbeta = fdata(beta,t)
> y<-inprod.fdata(x,fbeta)+rnorm(n,sd=0.1)
> 
> prx=x[1:100];pry=y[1:100]
> ind=101;ind2=102:110
> pr0=x[ind];pr10=x[ind2,]
> ndist=61
> gridy=seq(-1.598069,1.598069, len=ndist)
> # Conditional Function
> res1 = cond.F(pr10, gridy, prx, pry,p=1)
> # res2 = cond.F(pr10, gridy, prx, pry,h=0.3)
> # res3 = cond.F(pr10, gridy, prx, pry,g=0.25,h=0.3)
> 
> # plot(res1$Fc[,1],type="l",ylim=c(0,1))
> # lines(res2$Fc[,1],type="l",col=2)
> # lines(res3$Fc[,1],type="l",col=3)
> 
> 
> 
> 
> 
> 
> 
> cleanEx()
> nameEx("cond.mode")
> ### * cond.mode
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: cond.mode
> ### Title: Conditional mode
> ### Aliases: cond.mode
> ### Keywords: distribution
> 
> ### ** Examples
> 
> ## Not run: 
> ##D n= 500
> ##D t= seq(0,1,len=101)
> ##D beta = t*sin(2*pi*t)^2
> ##D x = matrix(NA, ncol=101, nrow=n)
> ##D y=numeric(n)
> ##D x0<-rproc2fdata(n,seq(0,1,len=101),sigma="wiener")
> ##D x1<-rproc2fdata(n,seq(0,1,len=101),sigma=0.1)
> ##D x<-x0*3+x1
> ##D fbeta = fdata(beta,t)
> ##D y<-inprod.fdata(x,fbeta)+rnorm(n,sd=0.1)
> ##D prx=x[1:100];pry=y[1:100]
> ##D ind=101;ind2=101:110
> ##D pr0=x[ind];pr10=x[ind2]
> ##D ndist=161
> ##D gridy=seq(-1.598069,1.598069, len=ndist)
> ##D # Conditional Function
> ##D I=5
> ##D # Time consuming
> ##D res = cond.F(pr10[I], gridy, prx, pry, h=1)
> ##D mcond=cond.mode(res)
> ##D mcond2=cond.mode(res,method="diff")
> ## End(Not run)
> 
> 
> 
> 
> 
> cleanEx()
> nameEx("cond.quantile")
> ### * cond.quantile
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: cond.quantile
> ### Title: Conditional quantile
> ### Aliases: cond.quantile
> ### Keywords: distribution
> 
> ### ** Examples
> 
> 
> n= 100
> t= seq(0,1,len=101)
> beta = t*sin(2*pi*t)^2
> x = matrix(NA, ncol=101, nrow=n)
> y=numeric(n)
> x0<-rproc2fdata(n,seq(0,1,len=101),sigma="wiener")
> x1<-rproc2fdata(n,seq(0,1,len=101),sigma=0.1)
> x<-x0*3+x1
> fbeta = fdata(beta,t)
> y<-inprod.fdata(x,fbeta)+rnorm(n,sd=0.1)
> 
> prx=x[1:50];pry=y[1:50]
> ind=50+1;ind2=51:60
> pr0=x[ind];pr10=x[ind2]
> ndist=161
> gridy=seq(-1.598069,1.598069, len=ndist)
> ind4=5
> y0 = gridy[ind4]
> 
> ## Conditional median
> med=cond.quantile(qua=0.5,fdata0=pr0,fdataobj=prx,y=pry,fn=cond.F,h=1)
[1] "Fc= -0.114310938157184 with Conditional quantile= 0.5 , tol= 0.001  and iter= 9"
> 
> ## Not run
> ## Conditional CI 95% conditional
> # lo=cond.quantile(qua=0.025,fdata0=pr0,fdataobj=prx,y=pry,fn=cond.F,h=1)
> # up=cond.quantile(qua=0.975,fdata0=pr0,fdataobj=prx,y=pry,fn=cond.F,h=1)
> # print(c(lo,med,up))
> 
> 
> 
> 
> cleanEx()
> nameEx("create.fdata.basis")
> ### * create.fdata.basis
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: create.fdata.basis
> ### Title: Create Basis Set for Functional Data of fdata class
> ### Aliases: create.fdata.basis create.pc.basis create.pls.basis
> ###   create.raw.fdata
> ### Keywords: multivariate
> 
> ### ** Examples
> 
> data(tecator)
> basis.pc<-create.pc.basis(tecator$absorp.fdata,c(1,4,5))
> plot(basis.pc$basis,col=1)
> basis.pls<-create.pls.basis(tecator$absorp.fdata,y=tecator$y[,1],c(1,4,5))
> lines(basis.pls$basis,col=2)
> 
> basis.fd<-create.fdata.basis(tecator$absorp.fdata,c(1,4,5),
+ type.basis="fourier")
Warning in any(diff(dropind)) :
  coercing argument of type 'double' to logical
> plot(basis.pc$basis)
> basis.fdata<-create.fdata.basis(tecator$absorp.fdata,c(1,4,5),
+ type.basis="fourier",class.out="fdata")
Warning in any(diff(dropind)) :
  coercing argument of type 'double' to logical
> plot(basis.fd,col=2,lty=1)
> lines(basis.fdata,col=3,lty=1)
> 
> 
> 
> cleanEx()
> nameEx("dcor.test")
> ### * dcor.test
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: dcor.xy
> ### Title: Distance Correlation Statistic and t-Test
> ### Aliases: dcor.test dcor.dist bcdcor.dist dcor.xy
> ### Keywords: htest multivariate nonparametric
> 
> ### ** Examples
> 
> x<-rproc2fdata(100,1:50)
> y<-rproc2fdata(100,1:50)
> dcor.xy(x, y,test=TRUE)

	dcor t-test of independence

data:  D1 and D2
T = 0.16811, df = 4849, p-value = 0.4333
sample estimates:
Bias corrected dcor 
        0.002414109 

> dx <- metric.lp(x)
> dy <- metric.lp(y)
> dcor.test(dx, dy)

	dcor t-test of independence

data:  dx and dy
T = 0.16811, df = 4849, p-value = 0.4333
sample estimates:
Bias corrected dcor 
        0.002414109 

> bcdcor.dist(dx, dy)
[1] 0.002414109
> dcor.xy(x, y,test=FALSE)
[1] 0.8143895
> dcor.dist(dx, dy)
[1] 0.8143895
> 
> 
> 
> cleanEx()
> nameEx("dev.S")
> ### * dev.S
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: dev.S
> ### Title: The deviance score .
> ### Aliases: dev.S
> ### Keywords: utilities
> 
> ### ** Examples
> 
> 
> data(phoneme)
> mlearn<-phoneme$learn
> np<-ncol(mlearn)
> tt<-mlearn[["argvals"]]
> S1 <- S.NW(tt,2.5)
> gcv1 <- dev.S(mlearn$data[1,],obs=(sample(150)), 
+ S1,off=rep(1,150),offdf=3)
> gcv2 <- dev.S(mlearn$data[1,],obs=sort(sample(150)), 
+ S1,off=rep(1,150),offdf=3)
>  
> 
> 
> cleanEx()
> nameEx("dfv.test")
> ### * dfv.test
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: dfv.test
> ### Title: Delsol, Ferraty and Vieu test for no functional-scalar
> ###   interaction
> ### Aliases: dfv.test dfv.statistic
> ### Keywords: htest models regression
> 
> ### ** Examples
> 
> 
> ## Simulated example ##
> 
> X=rproc2fdata(n=50,t=seq(0,1,l=101),sigma="OU")
> 
> beta0=fdata(mdata=rep(0,length=101)+rnorm(101,sd=0.05),
+ argvals=seq(0,1,l=101),rangeval=c(0,1))
> beta1=fdata(mdata=cos(2*pi*seq(0,1,l=101))-(seq(0,1,l=101)-0.5)^2+
+ rnorm(101,sd=0.05),argvals=seq(0,1,l=101),rangeval=c(0,1))
> 
> # Null hypothesis holds
> Y0=drop(inprod.fdata(X,beta0)+rnorm(50,sd=0.1))
> 
> # Null hypothesis does not hold
> Y1=drop(inprod.fdata(X,beta1)+rnorm(50,sd=0.1))
> 
> # We use the CV bandwidth given by fregre.np
> # Do not reject H0
> dfv.test(X,Y0,h=fregre.np(X,Y0)$h.opt,B=100)
  |                                                                              |                                                                      |   0%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  17%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  23%  |                                                                              |=================                                                     |  24%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  40%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  44%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%  |                                                                              |=====================================                                 |  53%  |                                                                              |======================================                                |  54%  |                                                                              |======================================                                |  55%  |                                                                              |=======================================                               |  56%  |                                                                              |========================================                              |  57%  |                                                                              |=========================================                             |  58%  |                                                                              |=========================================                             |  59%  |                                                                              |==========================================                            |  60%  |                                                                              |===========================================                           |  61%  |                                                                              |===========================================                           |  62%  |                                                                              |============================================                          |  63%  |                                                                              |=============================================                         |  64%  |                                                                              |==============================================                        |  65%  |                                                                              |==============================================                        |  66%  |                                                                              |===============================================                       |  67%  |                                                                              |================================================                      |  68%  |                                                                              |================================================                      |  69%  |                                                                              |=================================================                     |  70%  |                                                                              |==================================================                    |  71%  |                                                                              |==================================================                    |  72%  |                                                                              |===================================================                   |  73%  |                                                                              |====================================================                  |  74%  |                                                                              |====================================================                  |  75%  |                                                                              |=====================================================                 |  76%  |                                                                              |======================================================                |  77%  |                                                                              |=======================================================               |  78%  |                                                                              |=======================================================               |  79%  |                                                                              |========================================================              |  80%  |                                                                              |=========================================================             |  81%  |                                                                              |=========================================================             |  82%  |                                                                              |==========================================================            |  83%  |                                                                              |===========================================================           |  84%  |                                                                              |============================================================          |  85%  |                                                                              |============================================================          |  86%  |                                                                              |=============================================================         |  87%  |                                                                              |==============================================================        |  88%  |                                                                              |==============================================================        |  89%  |                                                                              |===============================================================       |  90%  |                                                                              |================================================================      |  91%  |                                                                              |================================================================      |  92%  |                                                                              |=================================================================     |  93%  |                                                                              |==================================================================    |  94%  |                                                                              |==================================================================    |  95%  |                                                                              |===================================================================   |  96%  |                                                                              |====================================================================  |  97%  |                                                                              |===================================================================== |  98%  |                                                                              |===================================================================== |  99%  |                                                                              |======================================================================| 100%
	Delsol, Ferraty and Vieu test for no functional-scalar interaction

data:  Y=0+e
Tn(h=0.291) = 0.0168, p-value = 0.58

> # dfv.test(X,Y0,B=5000)
> 
> # Reject H0
> dfv.test(X,Y1,B=100)
  |                                                                              |                                                                      |   0%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  17%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  23%  |                                                                              |=================                                                     |  24%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  40%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  44%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%  |                                                                              |=====================================                                 |  53%  |                                                                              |======================================                                |  54%  |                                                                              |======================================                                |  55%  |                                                                              |=======================================                               |  56%  |                                                                              |========================================                              |  57%  |                                                                              |=========================================                             |  58%  |                                                                              |=========================================                             |  59%  |                                                                              |==========================================                            |  60%  |                                                                              |===========================================                           |  61%  |                                                                              |===========================================                           |  62%  |                                                                              |============================================                          |  63%  |                                                                              |=============================================                         |  64%  |                                                                              |==============================================                        |  65%  |                                                                              |==============================================                        |  66%  |                                                                              |===============================================                       |  67%  |                                                                              |================================================                      |  68%  |                                                                              |================================================                      |  69%  |                                                                              |=================================================                     |  70%  |                                                                              |==================================================                    |  71%  |                                                                              |==================================================                    |  72%  |                                                                              |===================================================                   |  73%  |                                                                              |====================================================                  |  74%  |                                                                              |====================================================                  |  75%  |                                                                              |=====================================================                 |  76%  |                                                                              |======================================================                |  77%  |                                                                              |=======================================================               |  78%  |                                                                              |=======================================================               |  79%  |                                                                              |========================================================              |  80%  |                                                                              |=========================================================             |  81%  |                                                                              |=========================================================             |  82%  |                                                                              |==========================================================            |  83%  |                                                                              |===========================================================           |  84%  |                                                                              |============================================================          |  85%  |                                                                              |============================================================          |  86%  |                                                                              |=============================================================         |  87%  |                                                                              |==============================================================        |  88%  |                                                                              |==============================================================        |  89%  |                                                                              |===============================================================       |  90%  |                                                                              |================================================================      |  91%  |                                                                              |================================================================      |  92%  |                                                                              |=================================================================     |  93%  |                                                                              |==================================================================    |  94%  |                                                                              |==================================================================    |  95%  |                                                                              |===================================================================   |  96%  |                                                                              |====================================================================  |  97%  |                                                                              |===================================================================== |  98%  |                                                                              |===================================================================== |  99%  |                                                                              |======================================================================| 100%
	Delsol, Ferraty and Vieu test for no functional-scalar interaction

data:  Y=0+e
 ----------- FAILURE REPORT -------------- 
 --- srcref --- 
 at ../../../../R/src/library/stats/R/htest.R#34: 
 --- package (from environment) --- 
stats
 --- call from context --- 
paste("p-value", if (substr(fp, 1L, 1L) == "<") fp else paste("=", 
    fp))
 --- call from argument --- 
if (substr(fp, 1L, 1L) == "<") fp else paste("=", fp)
 --- R stacktrace ---
where 1 at ../../../../R/src/library/stats/R/htest.R#34: paste("p-value", if (substr(fp, 1L, 1L) == "<") fp else paste("=", 
    fp))
where 2: print.htest(x)
where 3: (function (x, ...) 
UseMethod("print"))(x)

 --- value of length: 5 type: logical ---
[1] FALSE FALSE FALSE FALSE FALSE
 --- function from context --- 
function (..., sep = " ", collapse = NULL) 
.Internal(paste(list(...), sep, collapse))
<bytecode: 0x1d057b0>
<environment: namespace:base>
 --- function search by body ---
Function paste in namespace base has this body.
 ----------- END OF FAILURE REPORT -------------- 
Fatal error: the condition has length > 1
