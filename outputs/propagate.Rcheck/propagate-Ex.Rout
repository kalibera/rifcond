
R Under development (unstable) (2018-01-22 r74151) -- "Unsuffered Consequences"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "propagate"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> library('propagate')
Loading required package: MASS
Loading required package: tmvtnorm
Loading required package: mvtnorm
Loading required package: Matrix
Loading required package: stats4
Loading required package: gmm
Loading required package: sandwich
Loading required package: Rcpp
Loading required package: ff
Loading required package: bit
Attaching package bit
package:bit (c) 2008-2012 Jens Oehlschlaegel (GPL-2)
creators: bit bitwhich
coercion: as.logical as.integer as.bit as.bitwhich which
operator: ! & | xor != ==
querying: print length any all min max range sum summary
bit access: length<- [ [<- [[ [[<-
for more help type ?bit

Attaching package: ‘bit’

The following object is masked from ‘package:base’:

    xor

Attaching package ff
- getOption("fftempdir")=="/var/scratch2/tomas/tmp/RtmpccCRTA"

- getOption("ffextension")=="ff"

- getOption("ffdrop")==TRUE

- getOption("fffinonexit")==TRUE

- getOption("ffpagesize")==65536

- getOption("ffcaching")=="mmnoflush"  -- consider "ffeachflush" if your system stalls on large writes

- getOption("ffbatchbytes")==16777216 -- consider a different value for tuning your system

- getOption("ffmaxbytes")==536870912 -- consider a different value for tuning your system


Attaching package: ‘ff’

The following objects are masked from ‘package:bit’:

    clone, clone.default, clone.list

The following objects are masked from ‘package:utils’:

    write.csv, write.csv2

The following objects are masked from ‘package:base’:

    is.factor, is.ordered

Loading required package: minpack.lm
> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> base::assign(".old_wd", base::getwd(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("WelchSatter")
> ### * WelchSatter
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: WelchSatter
> ### Title: Welch-Satterthwaite approximation to the 'effective degrees of
> ###   freedom'
> ### Aliases: WelchSatter
> ### Keywords: matrix multivariate algebra
> 
> ### ** Examples
> 
> ## Taken from GUM H.1.6, 4).
> WelchSatter(ui = c(25, 9.7, 2.9, 16.6), df = c(18, 25.6, 50, 2), uc = 32, alpha = 0.01)
$ws.df
[1] 17.47182

$k
[1] 2.898231

$u.exp
[1] 92.74338

> 
> 
> 
> cleanEx()
> nameEx("bigcor")
> ### * bigcor
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: bigcor
> ### Title: Creating very large correlation/covariance matrices
> ### Aliases: bigcor
> ### Keywords: matrix multivariate algebra
> 
> ### ** Examples
> 
> ## Small example to prove similarity
> ## to standard 'cor'. We create a matrix
> ## by subsetting the complete 'ff' matrix.
> MAT <- matrix(rnorm(70000), ncol = 700)
> COR <- bigcor(MAT, size= 500, fun = "cor")
bigcor: #1: Correlation of Block 1 and Block 1 (500 x 500) ... 
bigcor: 0.202999999999999s

bigcor: #2: Correlation of Block 1 and Block 2 (500 x 200) ... 
bigcor: 0.940999999999999s

bigcor: #3: Correlation of Block 2 and Block 2 (200 x 200) ... 
bigcor: 1.435s

> COR <- COR[1:nrow(COR), 1:ncol(COR)]
> all.equal(COR, cor(MAT)) # => TRUE
[1] TRUE
> 
> ## Not run: 
> ##D ## Example for cor(x, y) with 
> ##D ## y = small matrix.
> ##D MAT1 <- matrix(rnorm(50000), nrow = 10)
> ##D MAT2 <- MAT1[, 4950:5000]
> ##D COR <- cor(MAT1, MAT2)
> ##D BCOR <- bigcor(MAT1, MAT2)
> ##D BCOR <- BCOR[1:5000, 1:ncol(BCOR)] # => convert 'ff' to 'matrix'
> ##D all.equal(COR, BCOR)
> ##D 
> ##D ## Create large matrix.
> ##D MAT <- matrix(rnorm(137500), ncol = 13750)
> ##D COR <- bigcor(MAT, size= 2000, fun = "cor")
> ##D 
> ##D ## Extract submatrix.
> ##D SUB <- COR[1:3000, 1:3000]
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("cor2cov")
> ### * cor2cov
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: cor2cov
> ### Title: Converting a correlation matrix into a covariance matrix
> ### Aliases: cor2cov
> ### Keywords: matrix multivariate algebra
> 
> ### ** Examples
> 
> ## Example in Annex H.2 from the GUM 2008 manual
> ## (see 'References'), simultaneous resistance
> ## and reactance measurement.
> data(H.2)
> attach(H.2)
> 
> ## Original covariance matrix.
> COV <- cov(H.2)
> ## extract variances
> VAR <- diag(COV)
> 
> ## cor2cov covariance matrix.
> COV2 <- cor2cov(cor(H.2), VAR) 
> 
> ## Equal to original covariance matrix.
> all.equal(COV2, COV)
[1] TRUE
> 
> 
> 
> cleanEx()

detaching ‘H.2’

> nameEx("datasets")
> ### * datasets
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: datasets
> ### Title: Datasets from the GUM "Guide to the expression of uncertainties
> ###   in measurement" (2008)
> ### Aliases: H.2 H.3 H.4
> ### Keywords: datasets
> 
> ### ** Examples
> 
> ## See "Examples" in 'propagate'.
> 
> 
> 
> cleanEx()
> nameEx("fitDistr")
> ### * fitDistr
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: fitDistr
> ### Title: Fitting distributions to observations/Monte Carlo simulations
> ### Aliases: fitDistr
> ### Keywords: algebra univariate
> 
> ### ** Examples
> 
> ## Not run: 
> ##D ## Linear example, small error
> ##D ## => family of normal distributions.
> ##D EXPR1 <- expression(x + 2 * y)
> ##D x <- c(5, 0.01)
> ##D y <- c(1, 0.01)
> ##D DF1 <- cbind(x, y)
> ##D RES1 <- propagate(expr = EXPR1, data = DF1, type = "stat", 
> ##D                   do.sim = TRUE, verbose = TRUE)
> ##D fitDistr(RES1)$aic
> ##D 
> ##D ## Ratio example, larger error
> ##D ## => family of slightly skewed distributions.
> ##D EXPR2 <- expression(x/2 * y)
> ##D x <- c(5, 0.1)
> ##D y <- c(1, 0.02)
> ##D DF2 <- cbind(x, y)
> ##D RES2 <- propagate(expr = EXPR2, data = DF2, type = "stat", 
> ##D                   do.sim = TRUE, verbose = TRUE)
> ##D fitDistr(RES2)$aic
> ##D 
> ##D ## Exponential example, large error
> ##D ## => family of stronger skewed distributions.
> ##D EXPR3 <- expression(x^(2 * y))
> ##D x <- c(5, 0.1)
> ##D y <- c(1, 0.1)
> ##D DF3 <- cbind(x, y)
> ##D RES3 <- propagate(expr = EXPR3, data = DF3, type = "stat", 
> ##D                   do.sim = TRUE, verbose = TRUE)
> ##D fitDistr(RES3)$aic
> ##D 
> ##D ## Rectangular input distributions result
> ##D ## in trapezoidal output distribution.
> ##D A <- runif(100000, 20, 25)
> ##D B <- runif(100000, 3, 3.5)
> ##D DF4 <- cbind(A, B)
> ##D EXPR4 <- expression(A + B)
> ##D RES4 <- propagate(EXPR4, data = DF4, type = "sim", 
> ##D                  use.cov = FALSE, do.sim = TRUE)
> ##D fitDistr(RES4)$aic        
> ##D 
> ##D ## Fitting with 1/counts as weights.
> ##D EXPR5 <- expression(x + 2 * y)
> ##D x <- c(5, 0.05)
> ##D y <- c(1, 0.05)
> ##D DF5 <- cbind(x, y)
> ##D RES5 <- propagate(expr = EXPR5, data = DF5, type = "stat", 
> ##D                   do.sim = TRUE, verbose = TRUE, weights = TRUE)
> ##D fitDistr(RES5)$aic
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("interval")
> ### * interval
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: interval
> ### Title: Uncertainty propagation based on interval arithmetics
> ### Aliases: interval
> ### Keywords: matrix multivariate algebra
> 
> ### ** Examples
> 
> ## Example 1: even squaring of negative interval.
> EXPR1 <- expression(x^2)
> DAT1 <- data.frame(x = c(-1, 1))
> interval(DAT1, EXPR1)
[0, 1]> 
> ## Example 2: A complicated nonlinear model.
> ## Reduce sequence length to 2 => original interval
> ## for quicker evaluation.
> EXPR2 <- expression(C * sqrt((520 * H * P)/(M *(t + 460))))
> H <- c(64, 65)
> M <- c(16, 16.2)
> P <- c(361, 365)
> t <- c(165, 170)
> C <- c(38.4, 38.5)
> DAT2 <- makeDat(EXPR2)
> interval(DAT2, EXPR2, seq = 2)
[1317.494, 1352.277]> 
> ## Example 3: Body Mass Index taken from
> ## http://en.wikipedia.org/w/index.php?title=Interval_arithmetic
> EXPR3 <- expression(m/h^2)
> m <- c(79.5, 80.5)
> h <- c(1.795, 1.805)
> DAT3 <- makeDat(EXPR3)
> interval(DAT3, EXPR3)
[24.40129, 24.98429]> 
> ## Example 4: Linear model.
> EXPR4 <- expression(a * x + b)
> a <- c(1, 2)
> b <- c(5, 7)
> x <- c(2, 3)
> DAT4 <- makeDat(EXPR4)
> interval(DAT4, EXPR4)
[7, 13]> 
> ## Example 5: Overestimation from dependency problem.
> # Original interval with seq = 2 => [1, 7]
> EXPR5 <- expression(x^2 - x + 1)
> x <- c(-2, 1)
> DAT5 <- makeDat(EXPR5)
> interval(DAT5, EXPR5, seq = 2)
[1, 7]> 
> # Refine with large sequence => [0.75, 7]
> interval(DAT5, EXPR5, seq = 100)
[0.7502296, 7]> # Tallies with curve function.
> curve(x^2 - x + 1, -2, 1)
> 
> ## Example 6: Underestimation from dependency problem.
> # Original interval with seq = 2 => [0, 0]
> EXPR6 <- expression(x - x^2)
> x <- c(0, 1)
> DAT6 <- makeDat(EXPR6)
> interval(DAT6, EXPR6, seq = 2)
[0, 0]> 
> # Refine with large sequence => [0, 0.25]
> interval(DAT6, EXPR6, seq = 100)
[0, 0.2499745]> # Tallies with curve function.
> curve(x - x^2, 0, 1)
> 
> 
> 
> cleanEx()
> nameEx("makeDat")
> ### * makeDat
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: makeDat
> ### Title: Create a dataframe from the variables defined in an expression
> ### Aliases: makeDat
> ### Keywords: algebra univariate
> 
> ### ** Examples
> 
> ## Simulating from uniform
> ## and normal distribution,
> ## run 'propagate'.
> EXPR1 <- expression(a + b^c)
> a <- rnorm(100000, 12, 1)
> b <- rnorm(100000, 5, 0.1)
> c <- runif(100000, 6, 7)
> 
> DAT1 <- makeDat(EXPR1)
> propagate(EXPR1, DAT1, type = "sim", cov = FALSE)
Results from uncertainty propagation:
   Mean.1    Mean.2      sd.1      sd.2      2.5%     97.5% 
34856.158 38854.604 16787.149 17758.111  4049.317 73659.891 
Results from Monte Carlo simulation:
    Mean       sd   Median      MAD     2.5%    97.5% 
39021.69 18694.42 34736.94 19635.57 15354.95 80642.76 
> 
> 
> 
> cleanEx()
> nameEx("makeDerivs")
> ### * makeDerivs
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: makeDerivs
> ### Title: Utility functions for creating Gradient- and Hessian-like
> ###   matrices with symbolic derivatives and evaluating them in an
> ###   environment
> ### Aliases: makeGrad makeHess evalDerivs
> ### Keywords: array algebra multivariate
> 
> ### ** Examples
> 
> EXPR <- expression(a^b + sin(c))
> ENVIR <- list(a = 2, b = 3, c = 4)
> 
> ## First-order partial derivatives: Gradient.
> GRAD <- makeGrad(EXPR) 
> 
> ## This will evaluate the Gradient.
> evalDerivs(GRAD, ENVIR)
     [,1]     [,2]       [,3]
[1,]   12 5.545177 -0.6536436
> 
> ## Second-order partial derivatives: Hessian.
> HESS <- makeHess(EXPR) 
> 
> ## This will evaluate the Hessian.
> evalDerivs(HESS, ENVIR)
         [,1]      [,2]      [,3]
[1,] 12.00000 12.317766 0.0000000
[2,] 12.31777  3.843624 0.0000000
[3,]  0.00000  0.000000 0.7568025
> 
> ## Change derivatives order.
> GRAD <- makeGrad(EXPR, order = c(2,1,3)) 
> evalDerivs(GRAD, ENVIR)
         [,1] [,2]       [,3]
[1,] 5.545177   12 -0.6536436
> 
> 
> 
> cleanEx()
> nameEx("matrixStats")
> ### * matrixStats
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: matrixStats
> ### Title: Fast column- and row-wise versions of variance coded in C++
> ### Aliases: colVarsC rowVarsC
> ### Keywords: univar
> 
> ### ** Examples
> 
> ## Speed comparison on large matrix.
> ## ~ 110x speed increase!
> ## Not run: 
> ##D MAT <- matrix(rnorm(10 * 500000), ncol = 10)
> ##D system.time(RES1 <- apply(MAT, 1, var))
> ##D 
> ##D system.time(RES2 <- rowVarsC(MAT))
> ##D 
> ##D all.equal(RES1, RES2)
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("mixCov")
> ### * mixCov
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: mixCov
> ### Title: Aggregating covariances matrices and/or error vectors into a
> ###   single covariance matrix
> ### Aliases: mixCov
> ### Keywords: array algebra multivariate
> 
> ### ** Examples
> 
> #######################################################
> ## Example in Annex H.4.1 from the GUM 2008 manual
> ## (see 'References'), measurement of activity.
> ## This will give exactly the same values as Table H.8.
> data(H.4)
> attach(H.4)
> T0 <- 60
> lambda <- 1.25894E-4
> Rx <- ((Cx - Cb)/60) * exp(lambda * tx)
> Rs <- ((Cs - Cb)/60) * exp(lambda * ts)
> 
> mRx <- mean(Rx)
> sRx <- sd(Rx)/sqrt(6)
> mRx
[1] 652.6007
> sRx
[1] 6.416466
> 
> mRs <- mean(Rs)
> sRs <- sd(Rs)/sqrt(6)
> mRs
[1] 206.0881
> sRs
[1] 3.792532
> 
> R <- Rx/Rs
> mR <- mean(R)
> sR <- sd(R)/sqrt(6)
> mR
[1] 3.170186
> sR
[1] 0.04563322
> 
> cor(Rx, Rs)
[1] 0.6459873
> 
> ## Definition as in H.4.3.
> As <- c(0.1368, 0.0018)
> ms <- c(5.0192, 0.005)
> mx <- c(5.0571, 0.001)
> 
> ## We have to scale Rs/Rx by sqrt(6) to get the 
> ## corresponding covariances.
> Rs <- Rs/sqrt(6)
> Rx <- Rx/sqrt(6)
> 
> ## Here we create an aggregated covariance matrix
> ## from the raw and summary data.
> COV1 <- cov(cbind(Rs, Rx))
> COV <- mixCov(COV1, As[2]^2, ms[2]^2, mx[2]^2)
> COV
         Rs       Rx       As      ms    mx
Rs 14.38330 15.71988 0.00e+00 0.0e+00 0e+00
Rx 15.71988 41.17103 0.00e+00 0.0e+00 0e+00
As  0.00000  0.00000 3.24e-06 0.0e+00 0e+00
ms  0.00000  0.00000 0.00e+00 2.5e-05 0e+00
mx  0.00000  0.00000 0.00e+00 0.0e+00 1e-06
> 
> ## Prepare the data for 'propagate'.
> MEANS <- c(mRs, mRx, As[1], ms[1], mx[1])
> SDS <- c(sRs, sRx, As[2], ms[2], mx[2])
> DAT <- rbind(MEANS, SDS)
> colnames(DAT) <- c("Rs", "Rx", "As", "ms", "mx")
> 
> ## This will give exactly the same values as 
> ## in H.4.3/H.4.3.1.
> EXPR <- expression(As * (ms/mx) * (Rx/Rs))
> RES <- propagate(EXPR, data = DAT, cov = COV)
 ----------- FAILURE REPORT -------------- 
 --- srcref --- 
 at /var/scratch2/tomas/tmp/Rtmpy1PsSu/R.INSTALL729439f47221/propagate/R/propagate.R#60: 
 --- if/while statement is in package --- 
propagate
 --- call (currently evaluated) --- 
propagate(EXPR, data = DAT, cov = COV)
 --- R stacktrace ---
where 1: propagate(EXPR, data = DAT, cov = COV)

 --- value of length: 25 type: logical ---
      Rs    Rx    As    ms    mx
Rs FALSE FALSE FALSE FALSE FALSE
Rx FALSE FALSE FALSE FALSE FALSE
As FALSE FALSE FALSE FALSE FALSE
ms FALSE FALSE FALSE FALSE FALSE
mx FALSE FALSE FALSE FALSE FALSE
 --- function (currently evaluated)--- 
function(
expr, 
data, 
second.order = TRUE,
do.sim = TRUE, 
cov = TRUE, 
df = NULL,
nsim = 100000,
alpha = 0.05,
...
)
{            
  op <- options(warn = -1)
  on.exit(options(op))
  
  ## version 1.0-4: convert function to expression
  if (is.function(expr)) {
    ARGS <- as.list(args(expr))
    ARGS <- ARGS[-length(ARGS)]
    VARS <- names(ARGS)    
    expr <- body(expr)
    class(expr) <- "expression"
    isFun <- TRUE
  } else isFun <- FALSE
  
  ## check for correct expression and number of simulations
  if (!is.expression(expr)) stop("propagate: 'expr' must be an expression")
  if (nsim < 10000) stop("propagate: 'nsim' should be >= 10000 !")
  
  ## check for matching variable names
  if (!isFun) VARS <- all.vars(expr)  
  m <- match(VARS, colnames(data))
  if (any(is.na(m))) stop("propagate: variable names of input dataframe and expression do not match!")
  if (length(unique(m)) != length(m)) stop("propagate: some variable names are repetitive!")
  
  DATA <- as.matrix(data)
  EXPR <- expr
  
  ## create variables from input data
  ## version 1.0-5: check for simulated data => large nrow(data)
  if (nrow(data) > 3) {
    meanVAL <- apply(DATA, 2, function(x) mean(x, na.rm = TRUE))
    sdVAL <- apply(DATA, 2, function(x) sd(x, na.rm = TRUE))
    dfVAL <- NULL
    isRaw <- TRUE
  } else {
    meanVAL <- DATA[1, ]
    sdVAL <- DATA[2, ] 
    dfVAL <- if (nrow(DATA) == 3) DATA[3, ] else NULL
    isRaw <- FALSE
  }
       
  ## stat data: if no covariance matrix is supplied, create one with diagonal variances
  if (is.logical(cov) & !isRaw) {
    SIGMA <- diag(sdVAL^2, nrow = length(VARS), ncol = length(VARS))    
    colnames(SIGMA) <- rownames(SIGMA) <- colnames(DATA)
  } 
  
  ## raw data: if no covariance matrix is supplied, create one with off-diagonals or not
  if (cov & isRaw) {
    SIGMA <- cov(data)   
  } 
  if (!cov & isRaw) {
    SIGMA <- cov(data) 
    SIGMA[upper.tri(SIGMA)] <- SIGMA[lower.tri(SIGMA)] <- 0 
  } 
  
  ## if covariance matrix is supplied, check for symmetry and matching names
  if (is.matrix(cov)) {
    if (NCOL(cov) != NROW(cov)) stop("propagate: 'cov' is not a symmetric matrix!")
    m <- match(colnames(cov), colnames(DATA))            
    if (any(is.na(m))) stop("propagate: names of input dataframe and var-cov matrix do not match!")             
    if (length(unique(m)) != length(m)) stop("propagate: some names of the var-cov matrix are repetitive!")             
    SIGMA <- cov
  }
  
  ## version 1.0-5: replace possible NA's in covariance matrix with 0's
  SIGMA[is.na(SIGMA)] <- 0  
  
  ## version 1.0-5: No diagonals with 0, 
  ## otherwise tmvtnorm:::checkSymmetricPositiveDefinite throws an error!
  if (any(diag(SIGMA) == 0)) {
    DIAG <- diag(SIGMA)
    DIAG[DIAG == 0] <- 2E-16
    diag(SIGMA) <- DIAG
  }
  
  ## This will bring the variables in 'data' and 'expr' in the same 
  ## order as in the covariance matrix
  m1 <- match(colnames(SIGMA), colnames(DATA))
  meanVAL <- meanVAL[m1]
  m2 <- match(colnames(SIGMA), VARS)
  
  ############ first- and second-order Taylor expansion-based error propagation ################
  ## first-order mean: eval(EXPR)
  ## version 1.0-4: continue with NA's when differentiation not possible
  MEAN1 <- try(eval(EXPR, envir = as.list(meanVAL)), silent = TRUE)
  if (!is.numeric(MEAN1)) {
    message("propagate: there was an error in calculating the first-order mean")
    MEAN1 <- NA
  }  
  
  ## evaluate gradient vector
  GRAD <- try(makeGrad(EXPR, m2), silent = TRUE)  
  if (!inherits(GRAD, "try-error")) evalGRAD <- try(sapply(GRAD, eval, envir = as.list(meanVAL)), silent = TRUE)
  if (inherits(GRAD, "try-error")) evalGRAD <- try(numGrad(EXPR, as.list(meanVAL)), silent = TRUE)  
  if (!inherits(evalGRAD, "try-error")) evalGRAD <- as.vector(evalGRAD) else evalGRAD <- NA
  
  ## first-order variance: g.S.t(g) 
  VAR1 <- try(as.numeric(t(evalGRAD) %*% SIGMA %*% matrix(evalGRAD)), silent = TRUE)  
  if (inherits(VAR1, "try-error")) {
    message("propagate: there was an error in calculating the first-order variance")
    VAR1 <- NA
  }
 
  ## second-order mean: firstMEAN + 0.5 * tr(H.S) 
  if (second.order) {
    HESS <- try(makeHess(EXPR, m2), silent = TRUE)
    if (!inherits(HESS, "try-error")) evalHESS <- try(sapply(HESS, eval, envir = as.list(meanVAL)), silent = TRUE)
    if (inherits(HESS, "try-error")) evalHESS <- try(numHess(EXPR, as.list(meanVAL)), silent = TRUE)
    if (!inherits(evalHESS, "try-error")) evalHESS <- matrix(evalHESS, ncol = length(meanVAL), byrow = TRUE) else evalHESS <- NA  
    
    valMEAN2 <- try(0.5 * tr(evalHESS %*% SIGMA), silent = TRUE)
    if (!inherits(valMEAN2, "try-error")) {
      MEAN2 <- MEAN1 + valMEAN2
    } else {
      message("propagate: there was an error in calculating the second-order mean")
      MEAN2 <- NA
    }
    
    ## second-order variance: firstVAR + 0.5 * tr(H.S.H.S)
    valVAR2 <- try(0.5 * tr(evalHESS %*% SIGMA %*% evalHESS %*% SIGMA), silent = TRUE)
    if (!inherits(valVAR2, "try-error")) {
      VAR2 <- VAR1 + valVAR2
    } else {
      message("propagate: there was an error in calculating the second-order variance")
      VAR2 <- NA
    }
  } else MEAN2 <- VAR2 <- HESS <- evalHESS <- NA
  
  ## total mean and variance  
  if (second.order) totalVAR <- VAR2 else totalVAR <- VAR1
  if (second.order) totalMEAN <- MEAN2 else totalMEAN <- MEAN1
  errorPROP <- sqrt(totalVAR)  
  
  ## sensitivity index/contribution/relative contribution
  if (is.numeric(evalGRAD)) {
    sensitivity <- evalGRAD
    contribution <- outer(sensitivity, sensitivity, "*") * SIGMA
    rel.contribution <- abs(contribution)/sum(abs(contribution), na.rm = TRUE)
  } else sensitivity <- contribution <- rel.contribution <- NA
  
  ## WS degrees of freedom, coverage factor and expanded uncertainty
  if (!is.null(dfVAL)) dfVAL[is.na(dfVAL)] <- 1E6
  if (is.null(dfVAL)) dfVAL <- rep(1E6, ncol(DATA))
  ws <- WelchSatter(ui = sqrt(diag(SIGMA)), ci = sensitivity, df = dfVAL, dftot = df, uc = errorPROP, alpha = alpha)
  
  ## confidence interval based on either first- or second-order mean
  if (is.na(MEAN2)) confMEAN <- MEAN1 else confMEAN <- MEAN2
  confPROP <- confMEAN + c(-1, 1) * ws$u.exp
  names(confPROP) <- paste(c(alpha/2, 1 - alpha/2) * 100, "%", sep = "")
  
  ################## Monte-Carlo simulation using multivariate t-distribution #####################
  if (do.sim) {  
    if (is.na(ws$ws.df) | is.infinite(ws$ws.df)) DF <- 1E6 else DF <- ws$ws.df
    if (is.numeric(df)) DF <- 1E6
    
    ## if raw data, don't create Monte Carlo data
    if (!isRaw) {
      datSIM <- rtmvt(nsim, mean = meanVAL, sigma = SIGMA, df = floor(DF)) 
      colnames(datSIM) <- colnames(DATA)      
    } else datSIM <- DATA
      
    ## try vectorized evaluation, which is much faster  
    resSIM <- try(eval(EXPR, as.data.frame(datSIM)), silent = TRUE) 
    
    ## use 'row-wise' method if 'vectorized' throws an error
    if (inherits(resSIM, "try-error")) {
      message("propagate: using 'vectorized' evaluation gave an error. Switching to 'row-wise' evaluation...")
      resSIM <- apply(datSIM, 1, function(x) eval(EXPR, envir = as.list(x)))     
    }
    
    ## alpha-based confidence interval of MC simulations
    confSIM <- quantile(resSIM, c(alpha/2, 1 - (alpha/2)), na.rm = TRUE) 
    
    ## warning in case of single evaluated result
    if (length(unique(resSIM)) == 1) message("propagate: Monte Carlo simulation gave unique repetitive values! Are all derivatives constants?")   
  } else resSIM <- datSIM <- confSIM <- allSIM <- NA 
  
  
  outPROP <- c(Mean.1 = MEAN1, Mean.2 = MEAN2, sd.1 = sqrt(VAR1), sd.2 = sqrt(VAR2), 
               confPROP[1], confPROP[2])   
  
  outSIM <- c(Mean = mean(resSIM, na.rm = TRUE), sd = sd(resSIM, na.rm = TRUE), 
              Median = median(resSIM, na.rm = TRUE), MAD = mad(resSIM, na.rm = TRUE),
              confSIM[1], confSIM[2])
  
  OUT <- list(gradient = GRAD, evalGrad = evalGRAD,
              hessian = HESS, evalHess = evalHESS,
              rel.contr  = rel.contribution, covMat = SIGMA, ws.df = floor(ws$ws.df), 
              k = ws$k, u.exp = ws$u.exp, resSIM = resSIM, datSIM = datSIM, 
              prop = outPROP, sim = outSIM, expr = EXPR, data = DATA)
  
  class(OUT) <- "propagate"
  return(OUT)                                     
}
<bytecode: 0x158b9288>
<environment: namespace:propagate>
 --- function (body) search ---
Function propagate in namespace propagate has this body.
 ----------- END FAILURE REPORT -------------- 
Fatal error: the condition has length > 1 and only the first element will be used XXXXXX
